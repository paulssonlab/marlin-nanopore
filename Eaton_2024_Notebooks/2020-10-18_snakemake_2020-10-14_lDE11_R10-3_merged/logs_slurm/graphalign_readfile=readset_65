Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	graphalign
	1

[Sat Jan  6 18:26:20 2024]
rule graphalign:
    input: /home/de64/scratch/de64/sync_folder/2020-10-18_snakemake_2020-10-14_lDE11_R10-3_merged/ref.gfa, /home/de64/scratch/de64/sync_folder/2020-10-18_snakemake_2020-10-14_lDE11_R10-3_merged/reads/readset_65.fastq
    output: /home/de64/scratch/de64/sync_folder/2020-10-18_snakemake_2020-10-14_lDE11_R10-3_merged/graph_output/readset_65.gaf
    jobid: 0
    wildcards: readfile=readset_65
    resources: partition=short, time_min=10, mem_mb=4000, cpus=1, optflags=

GraphAligner bioconda 1.0.17-
GraphAligner bioconda 1.0.17-
unrecognised option '--high-memory'
run with option -h for help
[Sat Jan  6 18:26:21 2024]
Error in rule graphalign:
    jobid: 0
    output: /home/de64/scratch/de64/sync_folder/2020-10-18_snakemake_2020-10-14_lDE11_R10-3_merged/graph_output/readset_65.gaf
    shell:
        GraphAligner -g /home/de64/scratch/de64/sync_folder/2020-10-18_snakemake_2020-10-14_lDE11_R10-3_merged/ref.gfa -f /home/de64/scratch/de64/sync_folder/2020-10-18_snakemake_2020-10-14_lDE11_R10-3_merged/reads/readset_65.fastq -a /home/de64/scratch/de64/sync_folder/2020-10-18_snakemake_2020-10-14_lDE11_R10-3_merged/graph_output/readset_65.gaf -x dbg --high-memory -b 20 -B 35 -C -1
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
